{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9b1063-9aa8-47e2-922c-8e29e58e782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "sys.path.append('.')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from models.gat.gat_pytorch import GAT\n",
    "from models.gat import params as gat_params\n",
    "from utils.utils import *\n",
    "from runners import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "155d9b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.__version__\n",
    "import torch_geometric\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a735dd-e1a3-41c8-a2fd-66c58eab9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/lyz/co-phase-separation/PSGAT/')\n",
    "DATA_ROOT = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453705f1-c139-4beb-9e6e-1369ab0773c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction_cor(X, y, k=20):\n",
    "    cors = np.zeros((X.shape[1]))\n",
    "    \n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in range(X.shape[1]):\n",
    "        cor = np.corrcoef(X[:, i], y)[0, 1]\n",
    "        if not np.isnan(cor):\n",
    "            cors[i] = cor\n",
    "    \n",
    "    features = np.zeros_like(cors).astype(bool)\n",
    "    features[np.argsort(-cors)[:k]] = True\n",
    "    \n",
    "    return features, cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80a6111a-24ea-4199-bb57-467c4ac35481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(\n",
    "    ppi, # ['integrate', 'biogrid-all', 'biogrid-htp']\n",
    "    seqemb=False, # ProSE sequence embedding\n",
    "    expr=False, # Gene expression\n",
    "    subloc=False, # Sublocalization\n",
    "    gomf=False, # GO molecular function\n",
    "    comp=False, # GO cellular component\n",
    "    weights=False,\n",
    "    weights_thr=200, # edge weight threshold\n",
    "    max_feat_dim=150, # k in feature selection\n",
    "    seed=0 # random state\n",
    "):\n",
    "    # edges and edge_weights\n",
    "    ppi_path = os.path.join(\n",
    "        DATA_ROOT,           \n",
    "        f'PPIN/{ppi.upper()}.csv'\n",
    "    )\n",
    "    edges = pd.read_csv(ppi_path)\n",
    "    edge_weights = None\n",
    "    \n",
    "    if (ppi in ['string']) and (weights==True):      \n",
    "        key = 'combined_score'\n",
    "        edges = edges[edges.loc[:, key] > weights_thr].reset_index()\n",
    "        edge_weights = edges['combined_score'] / 1000\n",
    "        print(f'Filtered {ppi} network with thresh:', weights_thr)\n",
    "    \n",
    "    edges = edges[['A', 'B']].copy()\n",
    "    edges = edges.dropna()\n",
    "    edges, index = edges.values, edges.index.values\n",
    "    ppi_genes = np.union1d(edges[:, 0], edges[:, 1])\n",
    "    if edge_weights is not None:\n",
    "        edge_weights = edge_weights.iloc[index].values\n",
    "    \n",
    "    # labels\n",
    "    label_path = os.path.join(\n",
    "        DATA_ROOT,\n",
    "        f'Label/labels.csv'\n",
    "    )\n",
    "    labels = pd.read_csv(label_path).set_index('Gene')\n",
    "\n",
    "    ## filter labels not in the PPI network\n",
    "    print('Number of labels before filtering:', len(labels))\n",
    "    labels = labels.loc[np.intersect1d(labels.index, ppi_genes)].copy()\n",
    "    print('Number of labels after filtering:', len(labels))\n",
    "    \n",
    "    \"\"\"正负样本比例：1:1\"\"\"\n",
    "    ratio = 1\n",
    "    pos_samples = labels[labels['label']==1]\n",
    "    neg_samples = labels[labels['label']==0].sample(n=pos_samples.shape[0] * ratio, random_state=seed)\n",
    "    labels = pd.concat([pos_samples, neg_samples]).sort_index()\n",
    "    \n",
    "    ## train and test split\n",
    "    train_ds, test_ds = train_test_split(\n",
    "        labels,\n",
    "        test_size=.2,\n",
    "        random_state=seed,\n",
    "        stratify=labels\n",
    "    )\n",
    "    \n",
    "    genes = np.union1d(labels.index, ppi_genes)\n",
    "    print('Total number of genes:', len(genes))\n",
    "    \n",
    "    # node attributes\n",
    "    X = np.zeros((len(genes), 0))\n",
    "    X = pd.DataFrame(X, index=genes)\n",
    "    \n",
    "    ## ProSE sequence embedding\n",
    "    if seqemb:\n",
    "        seqemb_path = os.path.join(\n",
    "            DATA_ROOT,           \n",
    "            f'NodeFeat/SeqEmb/seqemb_80d.pkl'\n",
    "        )\n",
    "        seqemb_feat = pd.read_pickle(seqemb_path).set_index('entry')\n",
    "        columns = [f'seqemb_{i}' for i in range(seqemb_feat.shape[1])]\n",
    "        seqemb_feat.columns = columns\n",
    "        X = X.join(seqemb_feat, how='left')\n",
    "        print('Sequence Embedding dataset shape:', seqemb_feat.shape)\n",
    "    \n",
    "    ## Gene expression\n",
    "    \n",
    "    X = X.fillna(0)\n",
    "    \n",
    "    N = len(X)\n",
    "    mapping = dict(zip(genes, range(N)))\n",
    "    \n",
    "    # preprocessing\n",
    "    ## remove self-loops\n",
    "    mask = edges[:, 0] != edges[:, 1]\n",
    "    edges = edges[mask]\n",
    "    if edge_weights is not None:\n",
    "        edge_weights = edge_weights[mask]\n",
    "    \n",
    "    ## remove duplicated connections\n",
    "    df = pd.DataFrame(edges, columns=['A', 'B'])\n",
    "    df[0] = np.sort(df[['A', 'B']].values).sum(axis=1)\n",
    "    df = df.drop_duplicates(subset=0)\n",
    "    edges, index = df.iloc[:, :2].values, df.index.values\n",
    "    if edge_weights is not None:\n",
    "        edge_weights = edge_weights[index]\n",
    "        edge_weights = torch.tensor(edge_weights, dtype=torch.float32)\n",
    "    \n",
    "    edge_index = np.vectorize(mapping.__getitem__)(edges)\n",
    "    \n",
    "    ## node attribute matrix X\n",
    "    degrees = np.zeros((N, 1))\n",
    "    nodes, counts = np.unique(edge_index, return_counts=True)\n",
    "    degrees[nodes, 0] = counts\n",
    "    \n",
    "    if X is None or not X.shape[1]:\n",
    "        X = np.random.random((N, 80))\n",
    "\n",
    "    if X.shape[1] < 50:\n",
    "        X = np.concatenate([X, np.random.random((N, 50))], axis=1)\n",
    "        \n",
    "    # X = np.concatenate([X, degrees.reshape((-1, 1))], 1) # concat degree vector\n",
    "    X = X.to_numpy()\n",
    "    X = (X - X.mean(0, keepdims=True)) / (X.std(0, keepdims=True) + 1e-8) # normalization\n",
    "    \n",
    "    ## train and val split\n",
    "    train, val = train_test_split(\n",
    "        train_ds,\n",
    "        test_size=.05,\n",
    "        random_state=seed,\n",
    "        stratify=train_ds\n",
    "    )\n",
    "    \n",
    "    train_idx = [mapping[t] for t in train.index]\n",
    "    val_idx = [mapping[v] for v in val.index]\n",
    "    test_idx = [mapping[v] for v in test_ds.index]\n",
    "    \n",
    "    # feature selection\n",
    "    red_idx = np.concatenate([train_idx, test_idx, val_idx], axis=0)\n",
    "    red_y = np.concatenate([train.label, test_ds.label, val.label], axis=0)\n",
    "    feats, cors = dim_reduction_cor(\n",
    "        X[red_idx], \n",
    "        red_y.astype(np.float32), \n",
    "        k=max_feat_dim\n",
    "    )\n",
    "    X = X[:, feats]\n",
    "    \n",
    "    # Torch\n",
    "    edge_index = torch.from_numpy(edge_index.T)\n",
    "    edge_index = edge_index.to(torch.long).contiguous()\n",
    "    \n",
    "    X = torch.from_numpy(X).to(torch.float32)\n",
    "    train_y = torch.tensor(train.label.astype(int), dtype=torch.float32)\n",
    "    val_y = torch.tensor(val.label.astype(int), dtype=torch.float32)\n",
    "    test_y = torch.tensor(test_ds.label.astype(int), dtype=torch.float32)\n",
    "    \n",
    "    print(f'\\nNumber of edges in graph: {len(edges)}')\n",
    "    print(f'Number of nodes in graph: {len(X)}')\n",
    "    print(f'Shape of node features: {X.shape[0], X.shape[1]}\\n')\n",
    "    print('Using Edge Weights' if edge_weights is not None else 'Not using edge weights')\n",
    "    \n",
    "    return (edge_index, edge_weights), X, (train_idx, train_y), (val_idx, val_y), \\\n",
    "            (test_idx, test_y), genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7024c98c-f2f8-475b-ba66-6d4ff27d2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (edge_index, edge_weights), X, (train_idx, train_y), (val_idx, val_y), (test_idx, test_y), genes = data(ppi='biogrid-all', seqemb=True, weights_thr=250, weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e896a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb3f048-d03f-4aca-9647-e94e444807f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_0 = {\n",
    "    'lr': 0.005,\n",
    "    'weight_decay': 5e-4,\n",
    "    'h_feats': [8, 1],\n",
    "    'heads': [8, 1],\n",
    "    'dropout': 0.6,\n",
    "    'negative_slope': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9bab4c-98b1-4c49-983b-bf3d4101f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "431a655e-2b7f-441d-bafe-ffb4f7289802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss class\n",
    "class Loss():\n",
    "    def __init__(self, y, idx):\n",
    "        self.y = y\n",
    "        idx = np.array(idx)\n",
    "\n",
    "        self.y_pos = y[y == 1]\n",
    "        self.y_neg = y[y == 0]\n",
    "\n",
    "        self.pos = idx[y.cpu() == 1]\n",
    "        self.neg = idx[y.cpu() == 0]\n",
    "\n",
    "    def __call__(self, out):\n",
    "        loss_p = F.binary_cross_entropy_with_logits(\n",
    "            out[self.pos].squeeze(), self.y_pos)\n",
    "        loss_n = F.binary_cross_entropy_with_logits(\n",
    "            out[self.neg].squeeze(), self.y_neg)\n",
    "        loss = loss_p + loss_n\n",
    "        return loss\n",
    "\n",
    "# AUC calculation\n",
    "def evalAUC(model, X, A, y, mask, logits=None):\n",
    "    assert(model is not None or logits is not None)\n",
    "    if model is not None:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(X, A)\n",
    "            logits = logits[mask]\n",
    "    probs = torch.sigmoid(logits)\n",
    "    probs = probs.cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "    auc = metrics.roc_auc_score(y, probs)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y, probs)\n",
    "    return auc, fpr, tpr\n",
    "\n",
    "# Model training\n",
    "def train(\n",
    "    params,\n",
    "    X, A,\n",
    "    edge_weights,\n",
    "    train_y, train_idx,\n",
    "    val_y, val_idx,\n",
    "    savepath=''\n",
    "):\n",
    "    epochs = 1000\n",
    "    \n",
    "    model = GAT(in_feats=X.shape[1], **params)\n",
    "    model.to(DEVICE)\n",
    "    X = X.to(DEVICE)\n",
    "    A = A.to(DEVICE)\n",
    "    train_y = train_y.to(DEVICE)\n",
    "    val_y = val_y.to(DEVICE)\n",
    "    if edge_weights is not None:\n",
    "        edge_weights = edge_weights.to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params['lr'],\n",
    "        weight_decay=params['weight_decay']\n",
    "    )\n",
    "    loss_fnc = tools.Loss(train_y, train_idx)\n",
    "    val_loss_fnc = tools.Loss(val_y, val_idx)\n",
    "    \n",
    "    iterable = tqdm(range(epochs))\n",
    "    for i in iterable:\n",
    "        model.train()\n",
    "        logits = model(X, A, edge_weights=edge_weights)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fnc(logits)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        logits = logits.detach()\n",
    "        val_loss = val_loss_fnc(logits)\n",
    "        train_auc, _, _ = evalAUC(None, 0, 0, train_y, 0, logits[train_idx])\n",
    "        val_auc, _, _ = evalAUC(None, 0, 0, val_y, 0, logits[val_idx])\n",
    "        \n",
    "        tqdm.set_description(\n",
    "            iterable,\n",
    "            desc='Loss: %.4f; Val Loss %.4f; Train AUC %.4f. Validation AUC: %.4f' % (loss, val_loss, train_auc, val_auc)\n",
    "        )\n",
    "    \n",
    "    score, fpr, tpr = evalAUC(model, X, A, val_y, val_idx)\n",
    "    auc_dict = {\n",
    "        'auc': score,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr\n",
    "    }\n",
    "    print(f'Val AUC: {score}')\n",
    "    \n",
    "    return model, auc_dict\n",
    "\n",
    "# Model testing\n",
    "def test(model, X, A, test_ds=None):\n",
    "    model.to(DEVICE).eval()\n",
    "    X = X.to(DEVICE)\n",
    "    A = A.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(X, A)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    probs = probs.cpu().numpy()\n",
    "    \n",
    "    if test_ds is not None:\n",
    "        test_idx, test_y = test_ds\n",
    "        test_y = test_y.cpu().numpy()\n",
    "        # roc curve and auc\n",
    "        auc = metrics.roc_auc_score(test_y, probs[test_idx])\n",
    "        fpr, tpr, _ = metrics.roc_curve(test_y, probs[test_idx])\n",
    "        auc_dict = {\n",
    "            'auc': auc,\n",
    "            'fpr': fpr,\n",
    "            'tpr': tpr\n",
    "        }\n",
    "        # prc curve and auprc\n",
    "        precision, recall, _ = metrics.precision_recall_curve(test_y, probs[test_idx], pos_label=1)\n",
    "        auprc = metrics.auc(recall, precision)\n",
    "        auprc_dict = {\n",
    "            'auprc': auprc,\n",
    "            'pre': precision,\n",
    "            'rec': recall\n",
    "        }\n",
    "        return probs, auc_dict, auprc_dict\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e041324-6435-4e73-b28e-dd12dc9c59f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "models, preds, val_aucs, test_aucs, test_auprcs = (dict() for i in range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb56ad0f-3fa7-4d88-a87a-9a78db81558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n",
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1179; Val Loss 1.6313; Train AUC 0.7821. Validation AUC: 0.5249: 100%|██████████| 1000/1000 [00:25<00:00, 38.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5318877551020407\n",
      "Model_0, AUROC:0.610837948346359, AUPRC:0.5889589404417019\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4807; Val Loss 1.4070; Train AUC 0.5009. Validation AUC: 0.5517:   0%|          | 4/1000 [00:00<00:27, 36.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719; Val Loss 1.6822; Train AUC 0.7356. Validation AUC: 0.5064: 100%|██████████| 1000/1000 [00:24<00:00, 40.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5165816326530612\n",
      "Model_1, AUROC:0.5837689560581751, AUPRC:0.5764917668131786\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6011; Val Loss 1.7556; Train AUC 0.5151. Validation AUC: 0.4770:   0%|          | 4/1000 [00:00<00:25, 38.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2002; Val Loss 1.5854; Train AUC 0.7420. Validation AUC: 0.4860: 100%|██████████| 1000/1000 [00:25<00:00, 39.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.49362244897959184\n",
      "Model_2, AUROC:0.5891517002225558, AUPRC:0.5609512019649507\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6091; Val Loss 1.5031; Train AUC 0.5111. Validation AUC: 0.5255:   0%|          | 4/1000 [00:00<00:27, 36.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1617; Val Loss 1.6386; Train AUC 0.7578. Validation AUC: 0.5013: 100%|██████████| 1000/1000 [00:25<00:00, 39.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5982142857142858\n",
      "Model_3, AUROC:0.5702085813363698, AUPRC:0.5814421407271579\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5265; Val Loss 1.4357; Train AUC 0.5074. Validation AUC: 0.4911:   0%|          | 4/1000 [00:00<00:26, 37.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1294; Val Loss 1.4362; Train AUC 0.7705. Validation AUC: 0.6333: 100%|██████████| 1000/1000 [00:25<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.6683673469387755\n",
      "Model_4, AUROC:0.5292169142383935, AUPRC:0.5366328645648306\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5253; Val Loss 1.6484; Train AUC 0.5346. Validation AUC: 0.5191:   0%|          | 4/1000 [00:00<00:27, 36.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1751; Val Loss 1.4620; Train AUC 0.7613. Validation AUC: 0.5383: 100%|██████████| 1000/1000 [00:25<00:00, 39.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5994897959183674\n",
      "Model_5, AUROC:0.5042182081672791, AUPRC:0.4933552384534008\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6304; Val Loss 1.5948; Train AUC 0.4968. Validation AUC: 0.4330:   0%|          | 4/1000 [00:00<00:26, 37.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1284; Val Loss 1.3682; Train AUC 0.7744. Validation AUC: 0.6626: 100%|██████████| 1000/1000 [00:25<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.6785714285714285\n",
      "Model_6, AUROC:0.5788002691372083, AUPRC:0.5809800841146833\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8203; Val Loss 1.9251; Train AUC 0.4878. Validation AUC: 0.3189:   0%|          | 4/1000 [00:00<00:25, 39.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1776; Val Loss 1.9259; Train AUC 0.7419. Validation AUC: 0.6237: 100%|██████████| 1000/1000 [00:25<00:00, 39.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5561224489795918\n",
      "Model_7, AUROC:0.5833548988147612, AUPRC:0.5649710635507327\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5151; Val Loss 1.3875; Train AUC 0.4997. Validation AUC: 0.4974:   0%|          | 4/1000 [00:00<00:25, 38.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2133; Val Loss 1.5373; Train AUC 0.7056. Validation AUC: 0.4420: 100%|██████████| 1000/1000 [00:25<00:00, 39.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.4936224489795919\n",
      "Model_8, AUROC:0.5067543087831893, AUPRC:0.5046703749901394\n",
      "\n",
      "Number of labels before filtering: 20398\n",
      "Number of labels after filtering: 15939\n",
      "Total number of genes: 15939\n",
      "Sequence Embedding dataset shape: (20398, 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5603; Val Loss 1.6245; Train AUC 0.4935. Validation AUC: 0.4305:   0%|          | 4/1000 [00:00<00:27, 35.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of edges in graph: 239188\n",
      "Number of nodes in graph: 15939\n",
      "Shape of node features: (15939, 80)\n",
      "\n",
      "Not using edge weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2499; Val Loss 1.6707; Train AUC 0.6951. Validation AUC: 0.5842: 100%|██████████| 1000/1000 [00:25<00:00, 39.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val AUC: 0.5012755102040816\n",
      "Model_9, AUROC:0.5496092334765281, AUPRC:0.5470051880927262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(N):\n",
    "    (edge_index, edge_weights), X, (train_idx, train_y), (val_idx, val_y), (test_idx, test_y), genes = \\\n",
    "                                                    data(ppi='randomgraph', \n",
    "                                                         seqemb=True,\n",
    "                                                         weights_thr=0, \n",
    "                                                         weights=False, \n",
    "                                                         seed=i)\n",
    "    model, val_auc = train(gat_0, X, edge_index, edge_weights, train_y, train_idx, val_y, val_idx)\n",
    "    pred, test_auc, test_auprc = test(model, X, edge_index, (test_idx, test_y))\n",
    "#     break\n",
    "    models[i] = model\n",
    "    preds[i] = pred\n",
    "    val_aucs[i], test_aucs[i] = val_auc, test_auc\n",
    "    test_auprcs[i] = test_auprc\n",
    "    print('Model_{}, AUROC:{}, AUPRC:{}\\n'.format(i, test_auc['auc'], test_auprc['auprc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0e4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81b46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bebef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2def254-6295-49c4-b349-54dd65cd2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average AUC for validation set\n",
    "avgValAUC = np.mean([v['auc'] for v in val_aucs.values()])\n",
    "# average AUC for test set\n",
    "avgTestAUC = np.mean([v['auc'] for v in test_aucs.values()])\n",
    "# average AUPRC for test set\n",
    "avgTestAUPRC = np.mean([v['auprc'] for v in test_auprcs.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db819bf-9514-4d90-b2f2-c6eae8bd9cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC for val: 0.56, test: 0.56, AUPRC for test: 0.55\n"
     ]
    }
   ],
   "source": [
    "print('Average AUC for val: {:.2f}, test: {:.2f}, AUPRC for test: {:.2f}'.format(avgValAUC, avgTestAUC, avgTestAUPRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087b63f-b4b7-4f84-ab56-ab9cde4e4677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249ae4cf-7fbe-4e92-bf97-fd947ba65639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 44.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# mkdir\n",
    "SAVE_ROOT = './saves/RANDGRAPH_ProSE80d_pos1neg1/'\n",
    "if not os.path.exists(SAVE_ROOT):\n",
    "    os.mkdir(SAVE_ROOT)\n",
    "    os.mkdir(os.path.join(SAVE_ROOT, f'embeddings/'))\n",
    "    os.mkdir(os.path.join(SAVE_ROOT, f'pairwise_cosine/'))\n",
    "    os.mkdir(os.path.join(SAVE_ROOT, f'edge_cosine/'))\n",
    "    os.mkdir(os.path.join(SAVE_ROOT, f'models/'))\n",
    "    \n",
    "# save models\n",
    "for idx, model in tqdm(models.items()):\n",
    "    torch.save(model, os.path.join(SAVE_ROOT, f'models/model_{idx}.pt'))\n",
    "    torch.save(model.featuremap1.cpu(), os.path.join(SAVE_ROOT, f'embeddings/model_{idx}.pt'))\n",
    "\n",
    "# save results\n",
    "import pickle\n",
    "dict1 = {\n",
    "    'preds': preds,\n",
    "    'val_aucs': val_aucs,\n",
    "    'test_aucs': test_aucs,\n",
    "    'test_auprcs': test_auprcs,\n",
    "    'genes': genes\n",
    "}\n",
    "for key, val in dict1.items():\n",
    "    with open(os.path.join(SAVE_ROOT, f'{key}.pkl'), 'wb') as f:\n",
    "        pickle.dump(val, f)\n",
    "\n",
    "# with open('saved_dictionary.pkl', 'rb') as f:\n",
    "#     loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a740bd-2c84-43c5-b1a1-a182e93df3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27b421b4-682d-4ed5-9bc1-833e9bb59285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "def save_models(ppi, model):\n",
    "    ppi_path = os.path.join(\n",
    "        DATA_ROOT,           \n",
    "        f'PPIN/{ppi.upper()}.csv'\n",
    "    )\n",
    "    edges = pd.read_csv(ppi_path)\n",
    "\n",
    "    featuremap = model.featuremap1.cpu()\n",
    "    featuremap_cosine = pd.DataFrame(cosine_similarity(featuremap))\n",
    "    featuremap_cosine.columns, featuremap_cosine.index = genes, genes\n",
    "\n",
    "    cosim_list = list()\n",
    "    for _, x in edges.iterrows():\n",
    "        cosim = featuremap_cosine[x['A']][x['B']]\n",
    "        cosim_list.append(cosim)\n",
    "    edges['cosim'] = cosim_list\n",
    "    edges.loc[edges['cosim'] < 0, 'cosim'] = 0\n",
    "    edges.loc[edges['cosim'] > 1, 'cosim'] = 1\n",
    "    \n",
    "    return featuremap_cosine, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93c8e066-2c4e-41cb-9dd5-7d8e8284e77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:22<00:00, 14.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# save node embeddings\n",
    "for idx, model in tqdm(models.items()):\n",
    "    featuremap_cosine, featuremap_edge = save_models('integrate', model)\n",
    "    featuremap_cosine.to_pickle(os.path.join(SAVE_ROOT, f'pairwise_cosine/model_{idx}.pkl'))\n",
    "    featuremap_edge.to_pickle(os.path.join(SAVE_ROOT, f'edge_cosine/model_{idx}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef70d67-f830-41f9-8a09-c56a085d6643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa5b040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
